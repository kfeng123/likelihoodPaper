\documentclass[11pt]{article}
 
\newcommand\CG[1]{\textcolor{red}{#1}}

\usepackage{lineno,hyperref}

\usepackage[margin=1 in]{geometry}
\renewcommand{\baselinestretch}{1.25}

\usepackage{authblk}
\usepackage{galois} % composition function \comp
\usepackage{bm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{amsthm}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{color}
\usepackage{booktabs}
\usepackage[page,title]{appendix}
%\renewcommand\appendixname{haha}
\usepackage{enumerate}
\usepackage{changepage}
\usepackage{datetime}
\newdate{date}{7}{15}{2020}

%%%%%%%%%%%%%%  Notations %%%%%%%%%%
\DeclareMathOperator{\mytr}{tr}
\DeclareMathOperator{\mydiag}{diag}
\DeclareMathOperator{\myrank}{Rank}
\DeclareMathOperator{\myP}{P}
\DeclareMathOperator{\myE}{E}
\DeclareMathOperator{\myVar}{Var}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\newcommand{\Ba}{\mathbf{a}}    \newcommand{\Bb}{\mathbf{b}}    \newcommand{\Bc}{\mathbf{c}}    \newcommand{\Bd}{\mathbf{d}}    \newcommand{\Be}{\mathbf{e}}    \newcommand{\Bf}{\mathbf{f}}    \newcommand{\Bg}{\mathbf{g}}    \newcommand{\Bh}{\mathbf{h}}    \newcommand{\Bi}{\mathbf{i}}    \newcommand{\Bj}{\mathbf{j}}    \newcommand{\Bk}{\mathbf{k}}    \newcommand{\Bl}{\mathbf{l}}
\newcommand{\Bm}{\mathbf{m}}    \newcommand{\Bn}{\mathbf{n}}    \newcommand{\Bo}{\mathbf{o}}    \newcommand{\Bp}{\mathbf{p}}    \newcommand{\Bq}{\mathbf{q}}    \newcommand{\Br}{\mathbf{r}}    \newcommand{\Bs}{\mathbf{s}}    \newcommand{\Bt}{\mathbf{t}}    \newcommand{\Bu}{\mathbf{u}}    \newcommand{\Bv}{\mathbf{v}}    \newcommand{\Bw}{\mathbf{w}}    \newcommand{\Bx}{\mathbf{x}}
\newcommand{\By}{\mathbf{y}}    \newcommand{\Bz}{\mathbf{z}}    
\newcommand{\bA}{\mathbf{A}}    \newcommand{\bB}{\mathbf{B}}    \newcommand{\bC}{\mathbf{C}}    \newcommand{\bD}{\mathbf{D}}    \newcommand{\bE}{\mathbf{E}}    \newcommand{\bF}{\mathbf{F}}    \newcommand{\bG}{\mathbf{G}}    \newcommand{\bH}{\mathbf{H}}    \newcommand{\bI}{\mathbf{I}}    \newcommand{\bJ}{\mathbf{J}}    \newcommand{\bK}{\mathbf{K}}    \newcommand{\bL}{\mathbf{L}}
\newcommand{\bM}{\mathbf{M}}    \newcommand{\bN}{\mathbf{N}}    \newcommand{\bO}{\mathbf{O}}    \newcommand{\bP}{\mathbf{P}}    \newcommand{\bQ}{\mathbf{Q}}    \newcommand{\bR}{\mathbf{R}}    \newcommand{\bS}{\mathbf{S}}    \newcommand{\bT}{\mathbf{T}}    \newcommand{\bU}{\mathbf{U}}    \newcommand{\bV}{\mathbf{V}}    \newcommand{\bW}{\mathbf{W}}    \newcommand{\bX}{\mathbf{X}}
\newcommand{\bY}{\mathbf{Y}}    \newcommand{\bZ}{\mathbf{Z}}    

\newcommand{\bfsym}[1]{\ensuremath{\boldsymbol{#1}}}

 \def\balpha{\bfsym \alpha}
 \def\bbeta{\bfsym \beta}
 \def\bgamma{\bfsym \gamma}             \def\bGamma{\bfsym \Gamma}
 \def\bdelta{\bfsym {\delta}}           \def\bDelta {\bfsym {\Delta}}
 \def\bfeta{\bfsym {\eta}}              \def\bfEta {\bfsym {\Eta}}
 \def\bmu{\bfsym {\mu}}                 \def\bMu {\bfsym {\Mu}}
 \def\bnu{\bfsym {\nu}}
 \def\btheta{\bfsym {\theta}}           \def\bTheta {\bfsym {\Theta}}
 \def\beps{\bfsym \varepsilon}          \def\bepsilon{\bfsym \varepsilon}
 \def\bsigma{\bfsym \sigma}             \def\bSigma{\bfsym \Sigma}
 \def\blambda {\bfsym {\lambda}}        \def\bLambda {\bfsym {\Lambda}}
 \def\bomega {\bfsym {\omega}}          \def\bOmega {\bfsym {\Omega}}
 \def\brho   {\bfsym {\rho}}
 \def\btau{\bfsym {\tau}}
 \def\bxi{\bfsym {\xi}}
 \def\bzeta{\bfsym {\zeta}}
% May add more in future.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\theoremstyle{plain}
\newtheorem{theorem}{\quad\quad Theorem}
\newtheorem{proposition}{\quad\quad Proposition}
\newtheorem{corollary}{\quad\quad Corollary}
\newtheorem*{lemma}{\quad\quad Lemma}
\newtheorem{example}{Example}
\newtheorem{assumption}{\quad\quad Assumption}
\newtheorem{condition}{\quad\quad Condition}

\theoremstyle{definition}
\newtheorem{remark}{\quad\quad Remark}
\theoremstyle{remark}



\title{Response to Reviewers\\
    ``
    On the Wilks phenomenon of Bayes factors and the integrated likelihood ratio test
    ''
}



\author[1]{Rui Wang}
\author[1,2]{Xingzhong Xu}
\affil[1]{
School of Mathematics and Statistics, Beijing Institute of Technology, Beijing 
    100081,China
}

\affil[2]{
Beijing Key Laboratory on MCAACI, Beijing Institute of Technology, Beijing 100081,China
}



\begin{document}
\maketitle
We are grateful to the AE for informing us a number of useful relevant papers and helpful comments.
He/she even provided us an example, namely binomial mixture model, which is very suitable for illustrating the advantages of the proposed method over the LRT.
We thank both reviewers for their valuable and helpful comments and critiques.
We have carefully revised our paper according to the comments and critiques and have made extensive modifications on the original manuscript.
Now the paper is much improved.
Below we respond to the AE and each reviewer in turn.

\section{Response to the AE}
\textbf{
    First, the fractional posterior is a special case of a Gibbs posterior, and $\sqrt{n}$ consistency of Gibbs posteriors has been around in the literature for a while; see, for example, the paper "An MCMC approach to classical estimation" by Chernozhukov and Hong as a representative example. This is particularly not surprising for the fractional posterior since roughly speaking, it keeps the center of the posterior unaffected for large n and reduces the variance by a scale
    factor depending on the fractional power - hence the classical Bernstein--von Mises phenomenon should go through for the fractional posterior under the same conditions as the exact posterior. I found the integrability condition in Proposition 2 to be somewhat strong in this regard.
}

\textbf{Answers:}
We thank the AE for informing the literature on the Gibbs posterior.
The fact that the fractional posterior is a special case of a Gibbs posterior is interesting, and we mention this connection in the revised paper.
I found that the results of \cite{Chernozhukov2003} require certain conditions on the likelihood and only bounded likelihood can satisfy their conditions.
Since we would like to include the unbounded likelihood case, we can not use the $\sqrt{n}$ consistency result in their paper.
We note that the assumptions of \cite{Chernozhukov2003} (that is, compact parameter space and continuous prior density) implies that the prior distribution is proper.
In fact, we found that most existing results on the consistency of posterior require that the prior is proper.
Since improper priors are often used for Bayes factor, existing results are not suitable for our purpose.
The integrability condition in Proposition 2 is
\begin{align*}
    \int_{\Theta} \exp\{ - c^* D_{1-t}(\theta_0 \| \theta )\} \pi(\theta) \, \mathrm d \theta < \infty.
\end{align*}
Note that if $\pi(\theta)$ is proper, then
\begin{align*}
    \int_{\Theta} \exp\{ - c^* D_{1-t}(\theta_0 \| \theta )\} \pi(\theta) \, \mathrm d \theta <
    \int_{\Theta} \pi(\theta) \, \mathrm d \theta = 1 < \infty.
\end{align*}
Hence the integrability condition is satisfied for any proper priors.
Furthermore, it also allows improper priors provided the tail probability of the prior density is not too thick.
Hence our integrability condition is very weak.
In the revised paper, we add a remark on this condition.


\textbf{
    The paper doesn't discuss recent advances in the frequentist literature. I would point out the article "Generalized likelihood ratio statistics and Wilks phenomenon" by Fan et al. as an example; this has been cited many times and the authors need to check what is there beyond the usual LRT. Also take a look at the paper "Geometric Understanding of Likelihood Ratio Statistics" by Fan et al. which among other things provides a Bayesian argument for the derivation of the classical Wilk's phenomenon.
}

\textbf{Answers:}
We thank the AE for informing us these references, which are reviewered in the revised paper.

\section{Response to reviewer 1}

\textbf{Major comments:}

\textbf{1.
    (Literature review) The paper proposes to use the Bayes factor as a test statistic for a significance test of the composite null hypothesis. I can hardly believe this idea is new. The paper does not mention any papers on this idea. I suggest to review the literature of significance test using Bayes factors or related issues. I also suggest to review the literature of large sample properties of Bayes factor, and to compare the results of this paper with existing results in the literature.
}

\textbf{Answers:}
Following the reviewer's suggestions, we improved the literature review in the revised paper.
The idea of using the Bayes factor as a test statistic is definitely not a new one, and we point out this point explicitly in the revised paper.
We add the following comment in the revised paper:
\begin{adjustwidth}{1.5em}{1.5em}
    \emph{
The idea is not new.                                                                                      
In fact, this methodology dates back at least to \cite{Good1967}, and has been considered by many
researchers since then.
\cite{Good1992} gave a review for some early literature using this idea.                                  
See \cite{Aerts2004}, \cite{zhou2018On} and \cite{Wang2020} for some recent applications of the idea. 
However, the idea has been mostly used for specific models and has not been 
systematically and rigorously studied for general models.                                  
One reason for this fact may be due to the Lindley's paradox, that is, the distribution of the Bayes factor depends heavily on the prior density; see, e.g., \cite{Shafer1982}. \ldots
}
\end{adjustwidth}

Following the reviewer's suggestion, we also comment on the literature of large sample properties of Bayes factor, as follow:
\begin{adjustwidth}{1.5em}{1.5em}
    \emph{
        In this work, we treat the Bayes factor and its variants as frequentist test statistics.
        Hence a closely related area of research is the frequentist properties of the Bayes factor.
        Most existing results in this area focus on the consistency of the Bayes factor; see \cite{berger2003approximations}, \cite{moreno2010},      \cite{WangMin2016}, \cite{Chatterjee2017} and the references therein.
        There are still relatively few researches on the asymptotic distribution of the Bayes factor.
        \cite{clarke1990information} derived the asymptotic distribution of the ratio of the marginal likelihood to the likelihood at the true parameter, which can be regarded as the Bayes factor for a point null hypothesis.
        \cite{Gelfand1994} derived formal approximations to the Bayas factor and some of its variants.
        In this work, in order to use the Bayes factor to construct frequentist tests, we give a thorough study of the asymptotic distribution of the Bayes factor and its variants for general models.
        Thess results are interesting in their own right.
}
\end{adjustwidth}

We add a remark below Theorem $1$ which gives a comparison of Theorem $1$ and the result in \cite{clarke1990information}:
\begin{adjustwidth}{1.5em}{1.5em}
    \emph{
            \cite{clarke1990information} 
            derived the asymptotic null distribution of 
            $$
            \frac{
                    {\int_{\Theta} p_n(\bX^{n}\theta) \pi(\theta)\, \mathrm d\theta}
            }
            {p_n(\bX^{n}\theta_0)}
            ,
            $$
            which can be regarded as the Bayes factor for the point null hypothesis, i.e., $p_0 = 0$.
            Theorem 1 extends their result and gives the asymptotic distribution of the general Bayes factor under both the null       hypothesis and the local alternative hypothesis.
            \cite{clarke1990information} imposed some conditions on the likelihood around the true parameter, which may not be easy to verify for some    moderately complex models.
            In comparison, Theorem 1 only assumes the likelihood can be expanded in a $n^{-1/2}$ neighborhood of the true parameter,   which is satisfied by most regular models.
}
\end{adjustwidth}

\textbf{
    2.
    (numerical examples: simulation studies and real applications) The paper does not have any numerical study. I suggest to include extensive simulation studies comparing existing significance tests such as the likelihood ratio test (LRT). If the Bayes factors in the paper are used in hypothesis testing, is there anything that the user needs to be careful about? Please include in simulation study examples in which LRT fails and examples with wide applications.
}

\textbf{Answers:}
We follow the reviewer's suggestion.
In the revised paper, we add simulations to examine the performance of the proposed method and compare it with the LRT.
The simulation examples include two difficult problems, that is, normal mixture model and binomial mixture model.
For these models, researchers have proved that the LRT has irregular behavior.
The testing problem for binomial mixture model has applications in genetics.
Numerical results show that the proposed method outperforms the LRT in terms of both test level and test power.

In the revised paper, we also discussed that the users needs to be careful about the degree of freedom when they deal with irregular models, as follows:

\begin{adjustwidth}{1.5em}{1.5em}
    \emph{
The proposed method is quite universal. 
However, when applied to irregular models, one needs to be careful about the freedom of the asymptotic chi-squared distribution.
For example, in Proposition 5 and Proposition 6, the freedom of the asymptotic chi-squared distribution is $1$ instead of $p-p_0 = 2$.
This phenomenon is essentially caused by the loss of identifiability of the mixture models.
In general, when the model has a loss of identifiability, the degree of freedom of the asymptotic chi-squred distribution may be less than $p-p_0$.
In this case, if the true degree of freedom is not easy to obtain, the user can simply use $p-p_0$ as the degree of freedom, and the resulting test can still preserve the test level.
Of course, this simple strategy may lead to decreased power.
}
\end{adjustwidth}


\textbf{
    3. (Choice of $a$ and $b$) According to Theorem $2$, there are many $a$ and $b$ such that $\Delta_{a,b}$ satisfies the Wilks phenomenon.
    In actual testing problem, what values of $a$ and $b$ would you suggest to use?
}

\textbf{Answers:}

Our results imply that the choice of $a$ and $b$ does not affect the Wilks phenomenon and asymptotic power provided $a$ and $b$ are fixed and $0<b<a<1$.
In the simulation studies of the revised paper, the default value is $a=2/3$ and $b= 1/3$.
we also add a simulation to examine the effect of $a$ and $b$ on the finite sample performance of the test procedure.
It turns out that the proposed methdod is not sensitive to the choice $a$ and $b$.
In practice, if there is no practical evidence for the choice of $a$ and $b$, one can simply choose $a = 2/3$ and $b = 1/3$.

\textbf{
    4. The paper discusses the fractional Bayes factor, the posterior Bayes factor and the integrated Bayes factor, but does not discuss the intrinsic Bayes factor. I suggest to include some discussion on the intrinsic Bayes factor. Can you get similar asymptotic results for the intrinsic Bayes factor?
}

\textbf{Answers:}
The asymptotic behavior of the intrinsic Bayes factor is relatively simple.
In the asymptotic sense, the intrinsic Bayes factor is equivalent to the Bayes factor with intrinsic priors; see, e.g., \cite{intrisicBayesFactor} and \cite{Moreno1998An}.
Simple examples show that the Bayes factor with intrinsic  priors does not have Wilks phenomenon.
Hence intrinsic Bayes factor can not be directly used as a frequentist test statistic.
This point is made clear in our paper.

\textbf{
    5. The paper gives one example (mixtures of normals) for which the LRT fails. One example for the argument for the Bayes factor as the test statistic is weak. Please give more examples and numerical examples.
}

\textbf{Answers:}
We follow the reviewer's suggestion.
In the revised paper, we add an example of binomial mixture model.
This model is useful in genetics.
It is known that the LRT for this model has complicated behavior.
We proved that the proposed method has Wilks phenomenon in this problem.
We also conduct simulations to examine the performance of the proposed method.
It turns out that the proposed method outperforms the LRT in terms of both test level and test power.

\textbf{Minor comments:}

\textbf{
1. 
P. 3. L. 19. variantional $\rightarrow$ variational
}

\textbf{Answers:}
The correction has been made.

\textbf{
2. Assumption 1. The term ``inner point'' is used but ``interior point'' is more standard term.
Also here $\Theta$ and $\tilde \Theta$ is assumed open and ``interior point'' assumption is not necessary.
}

\textbf{Answers:}
The correction has been made.
We drop the condition of ``interior point''.

\textbf{
    3. P. 5. L. 36. means $\rightarrow$ mean
}

\textbf{Answers:}
The correction has been made.



\textbf{
4.
Equation (1).
It is stated that null distribution of $\textbf{BF}_t(X_n)$ is free of the nuisance parameter if and only if $\frac{\left| I_{\xi | \nu} (\nu, \xi_0) \right|^{-1/2} \pi(\theta_0) }{\pi_0(\nu)} \equiv c$ for some constant $c$. But the formula in Theorem $1$ is slightly different.
It should be
\begin{align*}
\frac{\left| I_{\xi | \nu} (\nu, \xi_0) \right|^{-1/2} \pi(\theta_0) }{\pi_0(\nu_0)} \equiv c
\end{align*}
for some constant $c$.
If this is the case, the subsequence discussion needs to be modified.
}

\textbf{Answers:}
This problem is a little bit brain twisting.
But we think our original statement is correct.
In the paper, under the null hypothesis, we assume the true parameter is $\theta_0 = (\nu_0^\top, \xi_0^\top)^\top$.
Here $\xi_0$ is specified by the null hypothesis ($H: \xi = \xi_0$).
But $\nu_0$ is an unknown nuisance parameter.
Hence according to Theorem 1, to make the null distribution of $\text{BF}(\bX^n)$ free of the nuisance parameter $\nu_0$, one should require that
\begin{align*}
     \frac{\left| I_{\xi | \nu} (\nu_0, \xi_0) \right|^{-1/2} \pi(\theta_0) }{\pi_0(\nu_0)} \equiv c
\end{align*}
for any nuisance parameter $\nu_0$.
But the above statement is equivalent to say that
\begin{align*}
     \frac{\left| I_{\xi | \nu} (\nu, \xi_0) \right|^{-1/2} \pi(\theta_0) }{\pi_0(\nu)} \equiv c
\end{align*}
for any nuisance parameter $\nu$.



\textbf{
5.
Please include some discussion on Assumptions $2$ and $3$.
Please explain conditions in these assumptions.
}

\textbf{Answers:}
We follow the reviewer's suggestion.
In the revised paper, we add the following comment bellow Assumption 2:

\begin{adjustwidth}{1.5em}{1.5em}
    \emph{
            The first condition in Assumption 2 avoids infinite Kullback-Leibler divergence.
                %between $P_{\theta_0}$ and $P_{\theta}$ are finite
                %The negation of the second condition in Assumption \ref{assumption2019} is:
                %for every $
                %assumes that the distribution $P_\theta$ is deviated from.
            If the second condition in Assumption 2 does not hold, then there is a $\delta>0$ and a sequence of parameters             $\{\theta_n\}$ such that $\|\theta_n - \theta_0\| \geq \delta$ and $D_t(\theta_0 \| \theta_n ) \to 0  $.
            In this case, the model will suffer from loss of identifiability.
            Hence the second condition assumes that the model is identifiable in a reasonable sense.
            The third condition in Assumption 2 assumes that $D_t(\theta_0 \| \theta)$ has a reasonable Taylor approximation around    $\theta =\theta_0$; see, e.g., \cite{Erven2014}, Section III. H.
    }
\end{adjustwidth}

We add the following comment bellow Assumption 3:

\begin{adjustwidth}{1.5em}{1.5em}
    \emph{
        Assumption 3 assumes that the tail of the prior density is not too thick.
            To appreciate  the conditions,
            suppose $P_\theta$ is the  normal distribution $ \mathcal N( \theta, 1  )$ and $\theta_0 = 0$.
            Then the first two conditions of Assumption 3 becomes
            \begin{align*}
                    \int_{\Theta} \exp\left\{ -c^\dagger \theta^2 /2 \right\} \pi (\theta) \, \mathrm d \theta < \infty,
                    \quad
                    \int_{\Theta}  \theta^2 \exp\left\{ -c^\dagger \theta^2 /2 \right\} \pi (\theta) \, \mathrm d \theta < \infty.
            \end{align*}
            The above condition is satisfied for $\pi(\theta) \equiv 1$.
            This implies that Assumption 3 is weak and it allows improper priors.
    }
\end{adjustwidth}

\textbf{
6.
P. 18. L. 44.
It is said ``This equality holds for every $M>0$ and hence also for some $M_n \to \infty$.''
Please prove this statement.
}

\textbf{Answers:}

We have obtained that for any fixed $M>0$, 
    \begin{align*}
    & \int_{\left\{ \theta: \|\theta - \theta_0\| \leq M/\sqrt n \right\} }
    \exp \left\{-t R_n(\theta_0\| \theta) \right\} \pi(\theta)
    \, \mathrm d \theta
        \\
        =&
        (1+o_{P^n_{\theta_0}}(1))
        n^{-p/2}\pi(\theta_0)
        \exp\left\{ 
                \frac{t}{2}\Delta_{n,\theta_0}^\top  I({\theta_0})\Delta_{n,\theta_0}
        \right\}
        \\
        &
        \cdot
        \int_{\{h:\|h\|\leq M\}}\exp\left\{ -\frac{t}{2}(h-\Delta_{n,\theta_0})^\top  I({\theta_0})(h-\Delta_{n,\theta_0})\right\} \, \mathrm dh
        .
\end{align*}
We claim that this equality holds for every $M>0$ and hence also for some $M_n \to \infty$.

%In essence, this fact follows from the fact that convergence in probability is metrizable.
In essence, this claim follows from a result in mathematical analysis and the fact that convergence in probability is metrizable.
To make the proof more readable, we add a lemma in the revised paper (Lemma 2 in the revised paper).
\begin{lemma}
        Let $T_{m,n}$, $m = 1, 2,\dots$, $n = 1, 2,\dots$, be random variables such that for fixed $m$, $T_{m,n}$ converges in probability to $0$ as $n \to \infty$.
        Then there exists a sequence $\{h(n)\}$ such that $h(n) \to \infty$ and $T_{h(n), n}$ converges in probability to $0$ as $n \to \infty$.
        \label{lemma:MN}
\end{lemma}
Using this lemma, we can prove our claim as follow:

Note that for every fixed $M > 0$, the term $o_{P_{\theta_0}^n}(1)$ in the above equality converges in probability to $0$ as $n \to \infty$.
Hence by Lemma \ref{lemma:MN}, this term also converges in probability to $0$ for some $M_n \to \infty$.
%Hence the above equality holds for every $M>0$ and hence also for some $M_n\to \infty$.
Therefore the above equality still holds if we replace $M$ by $M_n$.

In the revised paper, we also simplify some other proofs to improve the readability of the paper.

\textbf{
7.
P. 24. L. 4.
A typo.
$L_t (\Theta ; \bX_n) \leq L_1^{1/t}(\Theta ; \bX_n) \rightarrow  L_t (\Theta ; \bX_n) \leq L_1^{t}(\Theta ; \bX_n) $.
}


\textbf{Answers:}
The correction has been made.

\textbf{
8.
P. 25.
In the integral of the displayed formula. $\pi(\theta | \bX_n) \rightarrow \pi_t (\theta | \bX_n)$.
}

\textbf{Answers:}
The correction has been made.
During the revision of the paper, we also corrected many other typos and mistakes.
We are sorry for such typos and mistakes.
%We have made much efforts to reduce typos and mistakes of the revised paper.

\section{Response to reviewer 2}
\textbf{
    1.
    Some related reference is missing such as Zhou and Guan (2018) JASA paper “On the Null Distribution of Bayes Factors in Linear Regression”.
    In this paper, they showed by considering the Bayes factor as a test statistics (like this submitted paper), they derived the null distribution of the Bayes factor for linear models, which is a weighted sum of chi-squared random variables.
    Even though this work is restricted to linear models under simple assumptions, it is worth to cite.
    Also, I believe that you can find more references that consider a Bayes factors as a test statistics in frequentist settings.
}

\textbf{Answers:}
We thank the reviewer for informing us this useful paper.
In the revised paper, we reviewed the literature that consider a Bayes factors as a frequentist test statistic, and add the following comment in the revised paper:
\begin{adjustwidth}{1.5em}{1.5em}
    \emph{
        \dots
%The idea is not new.                                                                                      
In fact, this methodology dates back at least to \cite{Good1967}, and has been considered by many
researchers since then.
\cite{Good1992} gave a review for some early literature using this idea.                                  
See \cite{Aerts2004}, \cite{zhou2018On} and \cite{Wang2020} for some recent applications of the idea. 
However, to the best of our knowledge, the idea has been mostly used for specific models and has not been 
systematically studied with full mathematical rigour for general models.                                  
One cause of this fact may be the Lindley's paradox, that is, the distribution of the Bayes factor        
depends heavily on the prior density; see, e.g., \cite{Shafer1982}. \ldots
}
\end{adjustwidth}
Following another reviewer's suggestion, we also comment on the literature of large sample properties of Bayes factor, as follow:
\begin{adjustwidth}{1.5em}{1.5em}
    \emph{
        In this work, we treat the Bayes factor and its variants as frequentist test statistics.
        Hence a closely related area of research is the frequentist properties of the Bayes factor.
        Most existing results in this area focus on the consistency of the Bayes factor; see \cite{berger2003approximations}, \cite{moreno2010},      \cite{WangMin2016}, \cite{Chatterjee2017} and the references therein.
        There are still relatively few researches on the asymptotic distribution of the Bayes factor.
        \cite{clarke1990information} derived the asymptotic distribution of the ratio of the marginal likelihood to the likelihood at the true parameter, which can be regarded as the Bayes factor for a point null hypothesis.
        \cite{Gelfand1994} derived formal approximations to the Bayas factor and some of its variants.
        In this work, in order to use the Bayes factor to construct frequentist tests, we give a thorough study of the asymptotic distribution of the Bayes factor and its variants for general models.
        Thess results fill a theoretical gap in the literature and are interesting in their own right.
}
\end{adjustwidth}

\textbf{
    2.
    On page 4, ``The prior $\pi(\theta)$ and $\pi_0 (\nu)$ may be improper\dots''.
    This is wrong in general.
    If they are improper, we cannot calculate the Bayes factor.
    Of course, I understand that even when the priors are improper, the fractional Bayes factor, introduced later, circumvents this issue.
    But, I think that it would be better to briefly note this point at the place of the sentence ``The prior $\pi(\theta)$ and $\pi_0 (\nu)$ may be improper\dots'', to avoid a confusion.
}

\textbf{Answers:}
We are not pretty sure if the statement ``\emph{If they are improper, we cannot calculate the Bayes factor}'' means that the Bayes factor is not well-defined or the Bayes factor is hard to compute.
Below we discuss these two points separately.

Indeed, if the prior $\pi(\theta)$ is improper, then the marginal density $\int_{\Theta} p_n (\bX^n | \theta) \pi(\theta) \, \mathrm d \theta$ may be infinite for certain models, especially for small sample size $n$.
That is, the Bayes factors with improper priors are not universally well-defined.
In fact, for some irregular models, the improper priors can not be used for any $n$.
For example, consider the normal mixture model $p(x| \mu ) = 0.5 \phi(x) + 0.5 \phi(x-\mu)$.
Then if the prior $\pi(\mu)$ is improper, then for any $n$,
\begin{align*}
    \int_{-\infty}^{+\infty}
    \prod_{i=1}^n p(x_i | \mu) \pi(\mu) \, \mathrm d \mu
    \geq
    \int_{-\infty}^{+\infty}
    \prod_{i=1}^n (0.5\phi(x_i)) \pi(\mu) \, \mathrm d \mu
    =
\prod_{i=1}^n (0.5\phi(x_i))
    \int_{-\infty}^{+\infty}
     \pi(\mu) \, \mathrm d \mu
     =+\infty.
\end{align*}
In this sence, the reviewer's comment is correct.
However, we think that including the case for improper priors is important for at least two reasons.
First, in the context of statistical decision theory, Bayes rules with improper priors are important.
In particular, \cite{Farrell1968Towards} Theorem 5.1 implies that, under very weak conditions, if $\int_{\tilde \Theta_0} \pi_0(\nu) \, \mathrm d \nu = 1$, $\int_\Theta \pi(\theta) \, \mathrm d \theta = +\infty$, then the test based on Bayes factor is \emph{admissible}.
Second, in Bayesian literature, many, if not most, popular priors for Bayes factors are improper.
Take the linear model for example, improper priors are often adopted for the variance parameter; see, e.g., \cite{Liang2008Mixtures}.
Hence we think that it is worthwhile to include the case of improper priors in our main theoretical results.
In contrast, most existing results on the frequentist properties of Bayes methods assume proper priors.

Now we turn to the computation issue.
If the priors are proper, a brute force method to compute the marginal likelihood is to sample the parameter from the prior $\pi(\theta)$ and then use the sampled parameters $\theta_1^*, \dots, \theta_B^*$ to calculate the average of the likelihood 
\begin{align*}
\int_{\Theta} p(\bX^n | \theta) \pi(\theta)\, \mathrm d \theta
\approx
\frac{1}{B} 
\sum_{i=1}^n
p(\bX^n | \theta_i^*)
.
\end{align*}
If the priors are improper, then one can not sample from the prior and the above method can not be directly applied.
In this sence, the reviewer's comment is correct.
Nevertheless, one can use the importance sampling method to remedy this problem.
Note that
\begin{align*}
\int_{\Theta} p(\bX^n | \theta) \pi(\theta)\, \mathrm d \theta
=
\int_{\Theta} p(\bX^n | \theta) \frac{\pi(\theta)}{\tilde \pi(\theta)}  \tilde \pi(\theta)  \, \mathrm d \theta
\end{align*}
where $\tilde \pi(\theta)$ is an appropriate proper prior.
Then one can sample from $\tilde \pi(\theta)$ and then compute the average of $p(\bX^n | \theta) {\pi(\theta)}/{\tilde \pi(\theta)}$.
Hence one can compute the Bayes factor even if the prior is improper.
The computation of the Bayes factor has been actively studied, see \cite{Friel2012} for a review.

We add the following comment in the revised paper:

\begin{adjustwidth}{1.5em}{1.5em}
    \emph{
In Bayesian literature, conventional Bayes factors often use improper priors for certain parameters, and
consequently, $\pi(\theta)$ and $\pi_0 (\nu)$ may be improper, that is, $\int_{\Theta} \pi(\theta) \,
\mathrm d \theta = + \infty$, $\int_{\tilde \Theta_0} \pi_0 (\nu) \, \mathrm d \nu  = + \infty$; see, e.
g., \cite{berger2001Obj}, Section 2.1.
To accomodate these cases, throughout the paper, $\pi(\theta)$ and $\pi_0(\nu)$ are allowed to be improper unless otherwise stated.
}
\end{adjustwidth}

%Indeed, for immproper priors, some Bayesian computation method can not be directly applied, for example ABC.
%In fact, it is a common practice to use improper prior for certain parameters.
%For example, for Bayes factor of linear model, popular choice of the prior for the variance parameter is improper; see, e.g., \cite{Liang2008Mixtures}.
%Therefore, although the computation of the Bayes factor is difficult, we think that it is not exact to say ``we cannot calculate the Bayes factor''.

\textbf{
    3. On line 31 on page 6, what is $f$?
}

\textbf{Answers:}
Here $f$ is a probability density function.
We are sorry that we did not explain the meaning of $f$ in the original paper.

\textbf{
    4. On line 38 on page 6, you may want to note an extra weakness of the traditional approach.
    When the prior density is proportional to a function of the determinant of the Fisher information, its prior normalizing constant is difficult to evaluate, and the normalizing constant is critical for the Bayes factor.
    Although you noted ``\dots Fisher information matrix has a complicated form\dots undesirable\dots'', it would be better to be more specific.
}

\textbf{Answers:}
%We thank the reviewer for this advice.
We agree that the original statement is not specific enough.
Following the reviewer's suggestion, we the following comment to the revised paper:
\begin{adjustwidth}{1.5em}{1.5em}
    \emph{
        Second, 
        in order to construct priors satisfying (2), the determinant of the Fisher information matrix should be evaluated, which is a difficult task for many models.
        Hence it may not be easy to construct priors satisfying (2), especially for complex models.
}
\end{adjustwidth}





\textbf{
    5. This theoretical work is investigated under assumed that the posterior achieves $\sqrt n$-consistency (or the posterior contraction rate is n −1/2 ).
    In many practical statistical models, the optimal posterior contraction rate would be slower than $n^{-1/2}$.
    These examples include high-dimensional sparse problem like $(\log p /n)^{1/2}$ or nonparametric function estimation $n^{-\beta / (2\beta + p)}$, where $\beta$ is a smoothing factor for the true function.
    Under these interesting models, can you extend this result to more general models?
}

\textbf{Answers:}
In this paper, we systematically investigate the low-dimensional parametric models.
It is possible to investigate the case for certain high-diensional problem, as we have done in \cite{Wang2020}.
It is also possible to investigate specific irregular models as we have done in the mixture examples.
%In the mixture examples, we only use the fact that the posterior contraction rate can achieve $ (\log n)^\alpha /\sqrt n$ for some $\alpha > 0$.
We believe the methodology can also be applied to nonparametric problem with a suitable modification.
However, it is hard to provide a general theory for these problems.
The application of the proposed method to challenging models is an interesting problem, but it is definitely beyond the scope of the current paper.
We would like to report further applications in the future.

\textbf{
    6. You proposed theoretical results on asymptotic null distribution of Bayes factor which is a linear transformation of a chi-square distribution.
    But, you have not considered any simulation works to examine finite sample behavior of the approximated distribution.
    In practice, the accuracy of the asymptotic null distribution with finite samples is of interest.
    You may want to show that this asymptotic null distribution is useful in practice, especially for complicated and practical models.
    The examples you considered (without simulation studies) are too simple and far from a practical point of view.
}

\textbf{Answers:}
We follow the reviewer's suggestion.
In the revised paper, we conduct simulations to examine the finite sample performance of the proposed method.
The simulation results show that the empirical size of the proposed method is very close to the nominal test level.
This indicates that our asymptotic results are useful.

In the revised paper, we consider four examples, including exponential family models, two normal mixture models and a newly added example of the binomial mixture model which arises in genetics.
It is known that the LRT for these problems has nonstandard behavior for these models.
For these models, we prove that the generalized FBF has Wilks phenomenon.
We also conduct simulation studies which show that the proposed method outperforms the LRT in terms of both test level and test power.

It is relatively simple to apply the proposed method to the examples.
However, we would like to point out that the normal mixture models and the binomial mixture model are irregular models and the LRT for these models are not very simple to use.
Take the second normal mixture model in the paper as an example.
For this model, the asymptotic distribution of the LRT is a difficult problem.
\cite{bickel1993} studied this problem, but they did not fully solve it.
\cite{LIU200461} gave the asymptotic null distribution of the LRT.
\cite{HALL2005158} derived the asymptotic power of the LRT.
According to the result of \cite{HALL2005158}, the LRT has trivial power under $n^{-1/2}$ local alternative hypothesis.
For this irregualar model, the generalized FBF still has Wilks phenomenon and has better performance than the LRT.
We think these examples illustrate the wide application scope of the proposed method.

It is interesing to use the proposed method to solve more complex problems.
But it is difficult to seriously investigate more problems within limited space.
Hence we would like to leave it for future work.

\textbf{
    7. This paper is lack of tuning parameter selection which will be critical in the hypothesis testing result.
    Theoretically, it can satisfy some simple conditions, but in practice how to choose the tuning parameters $a$ and $b$ is very important.
}

\textbf{Answers:}
This question is asked by both reviewers.
Our Answer is as follow:

Our results imply that the choice of $a$ and $b$ does not affect the Wilks phenomenon and asymptotic power provided $a$ and $b$ are fixed and $0<b<a<1$.
In the simulation studies of the revised paper, the default value is $a=2/3$ and $b= 1/3$.
we also add a simulation to examine the effect of $a$ and $b$ on the finite sample performance of the test procedure.
It turns out that the proposed methdod is not sensitive to the choice $a$ and $b$.
In practice, if there is no practical evidence for the choice of $a$ and $b$, one can simply choose $a = 2/3$ and $b = 1/3$.




\section{List of major changes}
\begin{itemize}
    \item 
We add an example of binomial mixture model.
It is known that the LRT for this model has complicated behavior.
We proved that the proposed method has Wilks phenomenon in this problem.
    \item
        We add simulations studies for the normal mixture model and the binomial mixture model.
    \item
        The literature review is much improved.
    \item
        We add many remarks to explain our results and assumptions.
    \item
        We modify and simplify some of the theoretical proofs.
\end{itemize}




\bibliographystyle{apalike}
\bibliography{mybibfile}

\end{document}
